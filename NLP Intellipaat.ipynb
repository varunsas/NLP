{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: singledispatch in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (3.4.0.3)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (1.12.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String\n",
    "cricket= \"After surprising the hosts in the first Test, Sri Lanka made a positive start to the second Test as well by bowling South Africa out for 222 before slightly losing their advantage towards the end of the day's play. The visitors lost three wickets in the final session before stumps, still trailing South Africa by 162 runs.Just as Sri Lanka's bowlers were on top of South Africa's batsmen for majority of their innings, South Africa's bowlers returned the favour. The only difference being Sri Lanka's batsmen found ways to negate their attack and keep them at bay, led by Lahiru Thirimanne's unbeaten 25, but only for a while as Dale Steyn and Kagiso Raba kept things tight.Rabada struck early in the session, ekeing the outside edge off skipper Dimuth Karunaratne. Quinton de Kock took a sharp catch with the ball dipping on him. Rabada thought he had Oshada Fernando soon after for a similar dismissal, but the umpire thought otherwise. South Africa went in for a review, only for it to be a terrible decision with daylight between bat and ball.\"     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['After',\n",
       " 'surprising',\n",
       " 'the',\n",
       " 'hosts',\n",
       " 'in',\n",
       " 'the',\n",
       " 'first',\n",
       " 'Test',\n",
       " ',',\n",
       " 'Sri',\n",
       " 'Lanka',\n",
       " 'made',\n",
       " 'a',\n",
       " 'positive',\n",
       " 'start',\n",
       " 'to',\n",
       " 'the',\n",
       " 'second',\n",
       " 'Test',\n",
       " 'as',\n",
       " 'well',\n",
       " 'by',\n",
       " 'bowling',\n",
       " 'South',\n",
       " 'Africa',\n",
       " 'out',\n",
       " 'for',\n",
       " '222',\n",
       " 'before',\n",
       " 'slightly',\n",
       " 'losing',\n",
       " 'their',\n",
       " 'advantage',\n",
       " 'towards',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'the',\n",
       " 'day',\n",
       " \"'s\",\n",
       " 'play',\n",
       " '.',\n",
       " 'The',\n",
       " 'visitors',\n",
       " 'lost',\n",
       " 'three',\n",
       " 'wickets',\n",
       " 'in',\n",
       " 'the',\n",
       " 'final',\n",
       " 'session',\n",
       " 'before',\n",
       " 'stumps',\n",
       " ',',\n",
       " 'still',\n",
       " 'trailing',\n",
       " 'South',\n",
       " 'Africa',\n",
       " 'by',\n",
       " '162',\n",
       " 'runs.Just',\n",
       " 'as',\n",
       " 'Sri',\n",
       " 'Lanka',\n",
       " \"'s\",\n",
       " 'bowlers',\n",
       " 'were',\n",
       " 'on',\n",
       " 'top',\n",
       " 'of',\n",
       " 'South',\n",
       " 'Africa',\n",
       " \"'s\",\n",
       " 'batsmen',\n",
       " 'for',\n",
       " 'majority',\n",
       " 'of',\n",
       " 'their',\n",
       " 'innings',\n",
       " ',',\n",
       " 'South',\n",
       " 'Africa',\n",
       " \"'s\",\n",
       " 'bowlers',\n",
       " 'returned',\n",
       " 'the',\n",
       " 'favour',\n",
       " '.',\n",
       " 'The',\n",
       " 'only',\n",
       " 'difference',\n",
       " 'being',\n",
       " 'Sri',\n",
       " 'Lanka',\n",
       " \"'s\",\n",
       " 'batsmen',\n",
       " 'found',\n",
       " 'ways',\n",
       " 'to',\n",
       " 'negate',\n",
       " 'their',\n",
       " 'attack',\n",
       " 'and',\n",
       " 'keep',\n",
       " 'them',\n",
       " 'at',\n",
       " 'bay',\n",
       " ',',\n",
       " 'led',\n",
       " 'by',\n",
       " 'Lahiru',\n",
       " 'Thirimanne',\n",
       " \"'s\",\n",
       " 'unbeaten',\n",
       " '25',\n",
       " ',',\n",
       " 'but',\n",
       " 'only',\n",
       " 'for',\n",
       " 'a',\n",
       " 'while',\n",
       " 'as',\n",
       " 'Dale',\n",
       " 'Steyn',\n",
       " 'and',\n",
       " 'Kagiso',\n",
       " 'Raba',\n",
       " 'kept',\n",
       " 'things',\n",
       " 'tight.Rabada',\n",
       " 'struck',\n",
       " 'early',\n",
       " 'in',\n",
       " 'the',\n",
       " 'session',\n",
       " ',',\n",
       " 'ekeing',\n",
       " 'the',\n",
       " 'outside',\n",
       " 'edge',\n",
       " 'off',\n",
       " 'skipper',\n",
       " 'Dimuth',\n",
       " 'Karunaratne',\n",
       " '.',\n",
       " 'Quinton',\n",
       " 'de',\n",
       " 'Kock',\n",
       " 'took',\n",
       " 'a',\n",
       " 'sharp',\n",
       " 'catch',\n",
       " 'with',\n",
       " 'the',\n",
       " 'ball',\n",
       " 'dipping',\n",
       " 'on',\n",
       " 'him',\n",
       " '.',\n",
       " 'Rabada',\n",
       " 'thought',\n",
       " 'he',\n",
       " 'had',\n",
       " 'Oshada',\n",
       " 'Fernando',\n",
       " 'soon',\n",
       " 'after',\n",
       " 'for',\n",
       " 'a',\n",
       " 'similar',\n",
       " 'dismissal',\n",
       " ',',\n",
       " 'but',\n",
       " 'the',\n",
       " 'umpire',\n",
       " 'thought',\n",
       " 'otherwise',\n",
       " '.',\n",
       " 'South',\n",
       " 'Africa',\n",
       " 'went',\n",
       " 'in',\n",
       " 'for',\n",
       " 'a',\n",
       " 'review',\n",
       " ',',\n",
       " 'only',\n",
       " 'for',\n",
       " 'it',\n",
       " 'to',\n",
       " 'be',\n",
       " 'a',\n",
       " 'terrible',\n",
       " 'decision',\n",
       " 'with',\n",
       " 'daylight',\n",
       " 'between',\n",
       " 'bat',\n",
       " 'and',\n",
       " 'ball',\n",
       " '.']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenizing\n",
    "cricket_tokens=word_tokenize(cricket)\n",
    "cricket_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 201)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cheking the type and number of tokens\n",
    "type(cricket_tokens),len(cricket_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Frequency of tokens\n",
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({\"'s\": 6,\n",
       "          ',': 8,\n",
       "          '.': 6,\n",
       "          '162': 1,\n",
       "          '222': 1,\n",
       "          '25': 1,\n",
       "          'Africa': 5,\n",
       "          'After': 1,\n",
       "          'Dale': 1,\n",
       "          'Dimuth': 1,\n",
       "          'Fernando': 1,\n",
       "          'Kagiso': 1,\n",
       "          'Karunaratne': 1,\n",
       "          'Kock': 1,\n",
       "          'Lahiru': 1,\n",
       "          'Lanka': 3,\n",
       "          'Oshada': 1,\n",
       "          'Quinton': 1,\n",
       "          'Raba': 1,\n",
       "          'Rabada': 1,\n",
       "          'South': 5,\n",
       "          'Sri': 3,\n",
       "          'Steyn': 1,\n",
       "          'Test': 2,\n",
       "          'The': 2,\n",
       "          'Thirimanne': 1,\n",
       "          'a': 6,\n",
       "          'advantage': 1,\n",
       "          'after': 1,\n",
       "          'and': 3,\n",
       "          'as': 3,\n",
       "          'at': 1,\n",
       "          'attack': 1,\n",
       "          'ball': 2,\n",
       "          'bat': 1,\n",
       "          'batsmen': 2,\n",
       "          'bay': 1,\n",
       "          'be': 1,\n",
       "          'before': 2,\n",
       "          'being': 1,\n",
       "          'between': 1,\n",
       "          'bowlers': 2,\n",
       "          'bowling': 1,\n",
       "          'but': 2,\n",
       "          'by': 3,\n",
       "          'catch': 1,\n",
       "          'day': 1,\n",
       "          'daylight': 1,\n",
       "          'de': 1,\n",
       "          'decision': 1,\n",
       "          'difference': 1,\n",
       "          'dipping': 1,\n",
       "          'dismissal': 1,\n",
       "          'early': 1,\n",
       "          'edge': 1,\n",
       "          'ekeing': 1,\n",
       "          'end': 1,\n",
       "          'favour': 1,\n",
       "          'final': 1,\n",
       "          'first': 1,\n",
       "          'for': 6,\n",
       "          'found': 1,\n",
       "          'had': 1,\n",
       "          'he': 1,\n",
       "          'him': 1,\n",
       "          'hosts': 1,\n",
       "          'in': 4,\n",
       "          'innings': 1,\n",
       "          'it': 1,\n",
       "          'keep': 1,\n",
       "          'kept': 1,\n",
       "          'led': 1,\n",
       "          'losing': 1,\n",
       "          'lost': 1,\n",
       "          'made': 1,\n",
       "          'majority': 1,\n",
       "          'negate': 1,\n",
       "          'of': 3,\n",
       "          'off': 1,\n",
       "          'on': 2,\n",
       "          'only': 3,\n",
       "          'otherwise': 1,\n",
       "          'out': 1,\n",
       "          'outside': 1,\n",
       "          'play': 1,\n",
       "          'positive': 1,\n",
       "          'returned': 1,\n",
       "          'review': 1,\n",
       "          'runs.Just': 1,\n",
       "          'second': 1,\n",
       "          'session': 2,\n",
       "          'sharp': 1,\n",
       "          'similar': 1,\n",
       "          'skipper': 1,\n",
       "          'slightly': 1,\n",
       "          'soon': 1,\n",
       "          'start': 1,\n",
       "          'still': 1,\n",
       "          'struck': 1,\n",
       "          'stumps': 1,\n",
       "          'surprising': 1,\n",
       "          'terrible': 1,\n",
       "          'the': 11,\n",
       "          'their': 3,\n",
       "          'them': 1,\n",
       "          'things': 1,\n",
       "          'thought': 2,\n",
       "          'three': 1,\n",
       "          'tight.Rabada': 1,\n",
       "          'to': 3,\n",
       "          'took': 1,\n",
       "          'top': 1,\n",
       "          'towards': 1,\n",
       "          'trailing': 1,\n",
       "          'umpire': 1,\n",
       "          'unbeaten': 1,\n",
       "          'visitors': 1,\n",
       "          'ways': 1,\n",
       "          'well': 1,\n",
       "          'went': 1,\n",
       "          'were': 1,\n",
       "          'while': 1,\n",
       "          'wickets': 1,\n",
       "          'with': 2})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in cricket_tokens:\n",
    "    fdist[i]=fdist[i]+1\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 11),\n",
       " (',', 8),\n",
       " ('a', 6),\n",
       " ('for', 6),\n",
       " (\"'s\", 6),\n",
       " ('.', 6),\n",
       " ('South', 5),\n",
       " ('Africa', 5),\n",
       " ('in', 4),\n",
       " ('Sri', 3)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ten most common tokens\n",
    "top_10= fdist.most_common(10)\n",
    "top_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## uni-gram, bi-gram, tri-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "black_smoke= \"Did you know there was a tower, where they look out to the land,To see the people quickly passing by\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Did',\n",
       " 'you',\n",
       " 'know',\n",
       " 'there',\n",
       " 'was',\n",
       " 'a',\n",
       " 'tower',\n",
       " ',',\n",
       " 'where',\n",
       " 'they',\n",
       " 'look',\n",
       " 'out',\n",
       " 'to',\n",
       " 'the',\n",
       " 'land',\n",
       " ',',\n",
       " 'To',\n",
       " 'see',\n",
       " 'the',\n",
       " 'people',\n",
       " 'quickly',\n",
       " 'passing',\n",
       " 'by']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black_smoke_token= word_tokenize(black_smoke)\n",
    "black_smoke_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Did', 'you'),\n",
       " ('you', 'know'),\n",
       " ('know', 'there'),\n",
       " ('there', 'was'),\n",
       " ('was', 'a'),\n",
       " ('a', 'tower'),\n",
       " ('tower', ','),\n",
       " (',', 'where'),\n",
       " ('where', 'they'),\n",
       " ('they', 'look'),\n",
       " ('look', 'out'),\n",
       " ('out', 'to'),\n",
       " ('to', 'the'),\n",
       " ('the', 'land'),\n",
       " ('land', ','),\n",
       " (',', 'To'),\n",
       " ('To', 'see'),\n",
       " ('see', 'the'),\n",
       " ('the', 'people'),\n",
       " ('people', 'quickly'),\n",
       " ('quickly', 'passing'),\n",
       " ('passing', 'by')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.bigrams(black_smoke_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Did', 'you', 'know'),\n",
       " ('you', 'know', 'there'),\n",
       " ('know', 'there', 'was'),\n",
       " ('there', 'was', 'a'),\n",
       " ('was', 'a', 'tower'),\n",
       " ('a', 'tower', ','),\n",
       " ('tower', ',', 'where'),\n",
       " (',', 'where', 'they'),\n",
       " ('where', 'they', 'look'),\n",
       " ('they', 'look', 'out'),\n",
       " ('look', 'out', 'to'),\n",
       " ('out', 'to', 'the'),\n",
       " ('to', 'the', 'land'),\n",
       " ('the', 'land', ','),\n",
       " ('land', ',', 'To'),\n",
       " (',', 'To', 'see'),\n",
       " ('To', 'see', 'the'),\n",
       " ('see', 'the', 'people'),\n",
       " ('the', 'people', 'quickly'),\n",
       " ('people', 'quickly', 'passing'),\n",
       " ('quickly', 'passing', 'by')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.trigrams(black_smoke_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Did', 'you', 'know', 'there', 'was', 'a'),\n",
       " ('you', 'know', 'there', 'was', 'a', 'tower'),\n",
       " ('know', 'there', 'was', 'a', 'tower', ','),\n",
       " ('there', 'was', 'a', 'tower', ',', 'where'),\n",
       " ('was', 'a', 'tower', ',', 'where', 'they'),\n",
       " ('a', 'tower', ',', 'where', 'they', 'look'),\n",
       " ('tower', ',', 'where', 'they', 'look', 'out'),\n",
       " (',', 'where', 'they', 'look', 'out', 'to'),\n",
       " ('where', 'they', 'look', 'out', 'to', 'the'),\n",
       " ('they', 'look', 'out', 'to', 'the', 'land'),\n",
       " ('look', 'out', 'to', 'the', 'land', ','),\n",
       " ('out', 'to', 'the', 'land', ',', 'To'),\n",
       " ('to', 'the', 'land', ',', 'To', 'see'),\n",
       " ('the', 'land', ',', 'To', 'see', 'the'),\n",
       " ('land', ',', 'To', 'see', 'the', 'people'),\n",
       " (',', 'To', 'see', 'the', 'people', 'quickly'),\n",
       " ('To', 'see', 'the', 'people', 'quickly', 'passing'),\n",
       " ('see', 'the', 'people', 'quickly', 'passing', 'by')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nltk.ngrams(black_smoke_token,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stemming(Stemming is the process of reducing a word to it's word stem by cutting off the beginning or the end)\n",
    "from nltk.stem import PorterStemmer\n",
    "pst=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('win', 'studi', 'buy')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"winning\"),pst.stem(\"studies\"),pst.stem(\"buying\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Lemmatisation is the process of reducing words into their lemma or dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Lemmatization\n",
    "\n",
    "from nltk.stem import wordnet\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer= WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_to_stem= [\"cats\",\"cacti\",\"geese\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats:cat\n",
      "cacti:cactus\n",
      "geese:goose\n"
     ]
    }
   ],
   "source": [
    "for i in words_to_stem:\n",
    "    print(i + \":\" + lemmatizer.lemmatize(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts of speech Tagging (POS)\n",
    "\n",
    "#### POS Tagging is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech\n",
    "\n",
    "####### words are categorized into 8 parts of speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun, Pronoun, Verb, Adverb, Adjective, Conjunction, Preposition, Interjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pos\n",
    "peace= \"What do you mean,'I dont believe in GOD'? I talk to him everyday.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What',\n",
       " 'do',\n",
       " 'you',\n",
       " 'mean',\n",
       " ',',\n",
       " \"'\",\n",
       " 'I',\n",
       " 'dont',\n",
       " 'believe',\n",
       " 'in',\n",
       " 'GOD',\n",
       " \"'\",\n",
       " '?',\n",
       " 'I',\n",
       " 'talk',\n",
       " 'to',\n",
       " 'him',\n",
       " 'everyday',\n",
       " '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peace_tokenize =word_tokenize(peace)\n",
    "peace_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('What', 'WP')]\n",
      "[('do', 'VB')]\n",
      "[('you', 'PRP')]\n",
      "[('mean', 'NN')]\n",
      "[(',', ',')]\n",
      "[(\"'\", \"''\")]\n",
      "[('I', 'PRP')]\n",
      "[('dont', 'NN')]\n",
      "[('believe', 'VB')]\n",
      "[('in', 'IN')]\n",
      "[('GOD', 'NNP')]\n",
      "[(\"'\", \"''\")]\n",
      "[('?', '.')]\n",
      "[('I', 'PRP')]\n",
      "[('talk', 'NN')]\n",
      "[('to', 'TO')]\n",
      "[('him', 'PRP')]\n",
      "[('everyday', 'NN')]\n",
      "[('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for i in peace_tokenize:\n",
    "    print(nltk.pos_tag([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mary= \"mary had a little lamb, whom she really loved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mary_tokenized= word_tokenize(mary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mary', 'NN')]\n",
      "[('had', 'VBD')]\n",
      "[('a', 'DT')]\n",
      "[('little', 'JJ')]\n",
      "[('lamb', 'NN')]\n",
      "[(',', ',')]\n",
      "[('whom', 'WP')]\n",
      "[('she', 'PRP')]\n",
      "[('really', 'RB')]\n",
      "[('loved', 'VBN')]\n"
     ]
    }
   ],
   "source": [
    "for i in mary_tokenized:\n",
    "    print(nltk.pos_tag([i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition\n",
    "####### Named Entity Recognition is the process of taking a string of text as input and identifying relevant nouns(people,places and organizations) that are mentioned in that string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Named entity recognition\n",
    "from nltk import ne_chunk\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "john= 'John lives in New York'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "john_token= word_tokenize(john)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('John', 'NNP'),\n",
       " ('lives', 'VBZ'),\n",
       " ('in', 'IN'),\n",
       " ('New', 'NNP'),\n",
       " ('York', 'NNP')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "john_tags= nltk.pos_tag(john_token)\n",
    "john_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (PERSON John/NNP) lives/VBZ in/IN (GPE New/NNP York/NNP))\n"
     ]
    }
   ],
   "source": [
    "john_ner= ne_chunk(john_tags)\n",
    "print(john_ner)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
